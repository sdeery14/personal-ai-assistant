# Implementation Plan: Proactive Assistant ("The Alfred Engine")

**Branch**: `011-proactive-assistant` | **Date**: 2026-02-22 | **Spec**: [spec.md](spec.md)
**Input**: Feature specification from `/specs/011-proactive-assistant/spec.md`

## Summary

Transform the assistant from reactive to proactive by combining conversational onboarding, behavioral pattern detection, scheduled task execution, and engagement-based calibration. The implementation adds 6 new agent tools, 5 new database tables, a custom asyncio scheduler, 3 new API endpoints, and a frontend schedule list page — all following existing codebase patterns (asyncpg services, `@function_tool` tools, conditional system prompts, Next.js pages).

## Technical Context

**Language/Version**: Python 3.11 (backend), TypeScript/Next.js 15 (frontend)
**Primary Dependencies**: FastAPI, OpenAI Agents SDK, asyncpg, Redis, croniter (new), structlog
**Storage**: PostgreSQL (5 new tables), Redis (scheduler locks, rate limiting)
**Testing**: pytest (unit), MLflow eval (behavior), Vitest (frontend)
**Target Platform**: Docker (Linux containers), Windows dev host
**Project Type**: Web application (Python API + Next.js frontend)
**Performance Goals**: Scheduled tasks execute within 60 seconds of scheduled time (SC-005). Scheduler poll interval: 30 seconds.
**Constraints**: Single-process scheduler (no Celery workers). Agent invocation for task execution uses non-streamed `Runner.run` to avoid asyncio deadlocks in background tasks.
**Scale/Scope**: Hundreds of scheduled tasks per user, not millions. Pattern detection across recent conversations, not full history.

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

| Principle | Status | Notes |
|-----------|--------|-------|
| I. Clarity over Cleverness | PASS | Each component is a single-purpose module: scheduler service, pattern service, engagement service, etc. No magic — all tools have explicit inputs/outputs. |
| II. Evaluation-First | PASS | New MLflow eval datasets for onboarding behavior, pattern detection, and scheduled task execution. Unit tests for all services. |
| III. Tool Safety | PASS | All new tools (`create_schedule`, `manage_schedule`, etc.) are schema-validated `@function_tool` functions with explicit input validation. Cron expressions validated before storage. |
| IV. Privacy by Default | PASS | All data scoped by `user_id`. Pattern evidence stored as context summaries, not raw messages. Profile endpoint only returns user's own data. |
| V. Consistent UX | PASS | Onboarding follows conversational pattern (not forms). Proactive suggestions always cite their basis. User can always ask "what do you know about me?" |
| VI. Performance & Cost | PASS | Scheduler uses efficient poll query (indexed `next_run_at`). Background agent runs use same token budget as interactive. Pattern detection is post-conversation, not per-message. |
| VII. Observability | PASS | Structured logging on all scheduler events, tool invocations, pattern detections, and engagement recordings. Task runs have duration_ms and status tracking. |
| VIII. Reproducible Environments | PASS | `croniter` added via `uv add croniter`. No ad-hoc installs. |

## Project Structure

### Documentation (this feature)

```text
specs/011-proactive-assistant/
├── plan.md              # This file
├── spec.md              # Feature specification
├── research.md          # Phase 0 research findings
├── data-model.md        # Database schema design
├── quickstart.md        # Verification scenarios
├── contracts/
│   ├── schedules-api.md # Read-only schedules REST API
│   ├── engagement-api.md # Read-only proactiveness REST API
│   └── agent-tools.md   # Agent tool specifications
├── checklists/
│   └── requirements.md  # Spec quality checklist
└── tasks.md             # Task breakdown (generated by /speckit.tasks)
```

### Source Code (repository root)

```text
# Backend (Python)
src/
├── services/
│   ├── scheduler_service.py     # Task scheduler loop, execution engine
│   ├── schedule_service.py      # Scheduled task CRUD operations
│   ├── pattern_service.py       # Pattern detection and storage
│   ├── engagement_service.py    # Engagement event tracking and calibration
│   └── proactive_service.py     # User profile aggregation, suggestion scoring
├── models/
│   ├── schedule.py              # ScheduledTask, TaskRun, enums
│   ├── pattern.py               # ObservedPattern model
│   └── engagement.py            # EngagementEvent, ProactivenessSettings
├── tools/
│   ├── create_schedule.py       # create_schedule tool
│   ├── manage_schedule.py       # manage_schedule tool (pause/resume/cancel)
│   ├── record_pattern.py        # record_pattern tool
│   ├── record_engagement.py     # record_engagement tool
│   ├── adjust_proactiveness.py  # adjust_proactiveness tool
│   └── get_user_profile.py      # get_user_profile tool
├── api/
│   ├── schedules.py             # GET /schedules, /schedules/{id}, /schedules/{id}/runs
│   └── proactive.py             # GET /proactive/settings, /proactive/profile
migrations/
│   └── 011_proactive_assistant.sql  # All 5 new tables

# Frontend (Next.js)
frontend/src/
├── app/(main)/schedules/
│   └── page.tsx                 # Read-only schedule list page
├── components/schedule/
│   ├── ScheduleList.tsx         # Paginated schedule list
│   └── ScheduleCard.tsx         # Individual schedule item card
├── hooks/
│   └── useSchedules.ts          # Schedule data fetching hook
└── types/
    └── schedule.ts              # TypeScript interfaces

# Tests
tests/unit/
├── test_schedule_service.py
├── test_scheduler_service.py
├── test_pattern_service.py
├── test_engagement_service.py
├── test_proactive_service.py
├── test_schedule_tools.py
├── test_pattern_tools.py
├── test_engagement_tools.py
├── test_schedules_api.py
└── test_proactive_api.py

# Evaluation
eval/
├── onboarding_golden_dataset.json
└── proactive_golden_dataset.json
```

**Structure Decision**: Follows the existing web application pattern (Python backend `src/` + Next.js `frontend/`). Each new capability gets its own service, model, and tool module — matching the established pattern from Features 004-010.

### Key Design Decisions

1. **Custom scheduler over library**: ~200 lines of asyncio + PostgreSQL + croniter, launched in `main.py` lifespan alongside the existing deferred email processor. Avoids heavy dependencies (Celery, SQLAlchemy). See [research.md](research.md#r1-scheduling-library).

2. **Conditional system prompts**: Onboarding vs proactive behavior selected at agent creation time based on user state (conversation count + `is_onboarded` flag). Same pattern as existing feature-specific prompts.

3. **Agent-based task execution**: Scheduled tasks invoke the full production agent with a synthetic prompt, not bare tool calls. This preserves personalization, memory context, and guardrails.

4. **Pattern detection as post-conversation analysis**: After each conversation (alongside episode summarization), the agent analyzes recent activity for patterns. Uses the `record_pattern` tool — same async fire-and-forget pattern as memory writes.

5. **Engagement feedback loop**: The `record_engagement` tool has a side effect of updating `proactiveness_settings` when thresholds are reached (3 dismissals → suppress type). This keeps calibration automatic without a separate background job.

## Complexity Tracking

No constitution violations to justify. All components follow existing patterns with minimal new abstractions.
